{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Article citations information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import math\n",
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://scholar.google.com/scholar?start=0&hl=en&cites=15486505894554216965\n"
     ]
    }
   ],
   "source": [
    "article_id = '15486505894554216965'\n",
    "url_generic = f'https://scholar.google.com/scholar?start={{}}&hl=en&cites={article_id}'\n",
    "NUM_ARTICLES_BY_PAGE = 10\n",
    "\n",
    "url = url_generic.format(0)\n",
    "print(url)\n",
    "cookie = {\n",
    "    'NID': '',\n",
    "    'GSP': ''\n",
    "}\n",
    "\n",
    "def get_soup(url):\n",
    "    html = requests.get(url, cookies=cookie).text\n",
    "    return BeautifulSoup(html)\n",
    "\n",
    "soup = get_soup(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_citations():\n",
    "    return int(soup.find(id='gs_ab_md').div.text.split()[1])\n",
    "\n",
    "def get_num_pages(num_citations):\n",
    "    return math.ceil(num_citations/NUM_ARTICLES_BY_PAGE)\n",
    "\n",
    "num_citations = get_num_citations()\n",
    "num_pages = get_num_pages(num_citations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_articles_data = []\n",
    "\n",
    "for page_num in range(num_pages):\n",
    "    url = url_generic.format(page_num * NUM_ARTICLES_BY_PAGE)\n",
    "    soup = get_soup(url)\n",
    "    gs_rs = soup.find_all('div', 'gs_r gs_or gs_scl')\n",
    "\n",
    "    raw_articles_data.extend(gs_rs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate Data collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert num_citations == len(raw_articles_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse Articles info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_title(article):\n",
    "    return article.find('h3', 'gs_rt').text\n",
    "\n",
    "def get_article_url(article):\n",
    "    article_url_tag = article.find('h3', 'gs_rt').a\n",
    "    return article_url_tag['href'] if article_url_tag else None\n",
    "\n",
    "def get_authors(article):\n",
    "    return ', '.join(author.text for author in article.find('div', 'gs_a').find_all('a'))\n",
    "\n",
    "def get_year(article):\n",
    "    year = re.findall(\"\\d{4}\", article.find('div', 'gs_a').text)\n",
    "    return int(year[-1]) if year else None\n",
    "\n",
    "def get_article_description(article):\n",
    "    return article.find('div', 'gs_rs').text\n",
    "\n",
    "def get_num_citations(article):\n",
    "    citations_info = article.find('div', 'gs_fl gs_flb').find_all('a')[2].text\n",
    "    valid_num = citations_info.startswith('Cited')\n",
    "    return  int(citations_info.split()[-1]) if valid_num else 0\n",
    "    \n",
    "def get_file_info(article):    \n",
    "    file_url = file_type = publisher = None\n",
    "    article_file = article.find('div', 'gs_or_ggsm')\n",
    "    \n",
    "    if article_file:\n",
    "        file_url = article_file.a['href']\n",
    "        file_type, publisher =  article_file.a.text.split()\n",
    "        file_type = file_type[1:-1].lower()\n",
    "\n",
    "    file_info = {\n",
    "        'file_url': file_url,\n",
    "        'file_type': file_type,\n",
    "        'publisher': publisher}\n",
    "    return file_info\n",
    "\n",
    "def get_article_data(article):\n",
    "\n",
    "    file_info = get_file_info(article)\n",
    "    \n",
    "    data = {\n",
    "        'title': get_title(article),\n",
    "        'article_url': get_article_url(article),\n",
    "        'authors': get_authors(article),\n",
    "        'year': get_year(article),\n",
    "        'article_description': get_article_description(article),\n",
    "        'num_citations': get_num_citations(article),\n",
    "        'file_url': file_info['file_url'],\n",
    "        'file_type': file_info['file_type'],\n",
    "        'publisher': file_info['publisher'],\n",
    "    }\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_data = []\n",
    "\n",
    "for article in raw_articles_data:\n",
    "    articles_data.append(get_article_data(article))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data_files/article_citations.json\", \"w\") as f:\n",
    "    json.dump(articles_data, f, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mldev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
